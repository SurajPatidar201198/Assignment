{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all necessary libraries\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import PIL\n",
    "import cv2\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import image\n",
    "from sklearn.datasets import load_files\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to load data from given path\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    doc_files = np.array(data['filenames'])\n",
    "    doc_targets = np_utils.to_categorical(np.array(data['target']), 16)\n",
    "    #print(np.array(data['filenames']))\n",
    "    #print(np.array(data['target']))\n",
    "    return doc_files, doc_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading data from appropriate directories\n",
    "train_files, train_targets = load_dataset('D:/Eduwaive Project/RVL_CDIP/train')\n",
    "valid_files, valid_targets = load_dataset('D:/Eduwaive Project/RVL_CDIP/validation')\n",
    "test_files, test_targets = load_dataset('D:/Eduwaive Project/RVL_CDIP/test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doc_name will give all different types of categories on which image is to be categorized\n",
    "doc_names = [item[35:-1] for item in (glob(\"D:/Eduwaive Project/RVL_CDIP/train/*/\"))]\n",
    "print(doc_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the dataset\n",
    "print('There are %d total doc categories.' % len(doc_names))\n",
    "print('There are %s total doc images.\\n' % len(np.hstack([train_files, valid_files])))\n",
    "print('There are %d training doc images.' % len(train_files))\n",
    "print('There are %d validation doc images.' % len(valid_files))\n",
    "print('There are %d test doc images.'% len(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that converts image into 4D array to facilitate Keras CNN\n",
    "def convert_4darray(img_path):\n",
    "    #loads image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    #convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    #convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funtion which converts all images in given path to 4D array for Keras CNN\n",
    "def convert_4darrays(img_paths):\n",
    "    list_of_tensors = [convert_4darray(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rescaling the images by dividing eveyr pixel in every image by 255 - preprocess data for Keras\n",
    "train_tensors = convert_4darrays(train_files).astype('float32')/255\n",
    "test_tensors = convert_4darrays(test_files).astype('float32')/255\n",
    "valid_tensors = convert_4darrays(valid_files).astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model Xception which is best for image classification but accuacy is low because of low training if we will train it on full dataset them it accuracy will increase \n",
    "base_model=keras.applications.xception.Xception(include_top=False, weights='imagenet', input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flatten layer\n",
    "x = Flatten()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = Dense(16, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=sgd,metrics=['accuracy'])\n",
    "EPOCHS=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fit_model = model.fit(train_tensors, train_targets,validation_data=(valid_tensors, valid_targets),epochs=EPOCHS, batch_size=5,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = 100*np.sum(np.array(predictions)==np.argmax(test_targets, axis=1))/len(predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)\n",
    "#print(len(predictions))\n",
    "#print(len(test_files))\n",
    "'''for i in range(len(test_files)):\n",
    "    print(test_files[i])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking our model output on random image \n",
    "test_image=image.load_img('01075756.tif',target_size=(224,224))\n",
    "test_image=image.img_to_array(test_image)\n",
    "test_image=np.expand_dims(test_image, axis = 0)#making the image in a single array as axis=0\n",
    "result=model.predict(test_image)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knowing which category the image belongs\n",
    "for i in result:\n",
    "    for j in range(16):\n",
    "        if int(i[j])==1:\n",
    "            print(j)\n",
    "            print(doc_names[j])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making 16 different folders to store the images as classified by the model\n",
    "import os\n",
    "os.chdir(\"C:/Users/sam/Documents/Intake\")\n",
    "os.mkdir(\"answers4\")\n",
    "os.chdir(\"C:/Users/sam/Documents/Intake/answers4\")\n",
    "\n",
    "for i in range(16):\n",
    "    os.mkdir(str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copying the image according as they are categorized\n",
    "import shutil\n",
    "\n",
    "for i in range(len(test_files)):\n",
    "    for j in range(16):\n",
    "        if predictions[i]==j:\n",
    "            shutil.copy2(test_files[i],'C:/Users/sam/Documents/Intake/answers4/'+str(j) +'/')\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#naming all the folders \n",
    "class_name={'0':'advertisement','1':'budget','2':'email','3':'file folder','4':'form','5':'handwritten','6':'invoice','7':'letter','8':'memo','9':'news article','10':'presentation','11':'questionnaire','12':'resume','13':'scientific publication','14':'scientific report','15':'specification'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = 'C:/Users/sam/Documents/Intake/answers4'\n",
    "\n",
    "i = 0\n",
    "for j in class_name.keys():\n",
    "    os.rename(path+'/'+j, path+'/'+class_name[j])\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
